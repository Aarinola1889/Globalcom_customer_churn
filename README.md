# Globalcom Telecom Customer Churn Prediction Project

## ğŸ“Œ Project Overview
This repository contains the assets for a **hypothetical business analytics project** focused on predicting customer churn for Globalcom telecommunications company. The purpose of this project is to demonstrate the end-to-end process of data collection, cleaning, transformation, and preparation for analysis and modeling.

**Note: This is an academic project. All company names, data, and specific results are hypothetical and created for demonstration purposes only.**

## ğŸ¯ Business Objective
The primary goal of this project is to build a predictive model that identifies customers with a high probability of churning. This would enable a targeted customer retention strategy, thereby reducing acquisition costs and increasing customer lifetime value.
Globalcom-Customer-Churn/
## ğŸ“ Repository Structure
The repository is organized as follows:
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ telco_churn_clean.csv # Final cleaned and transformed dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ 01_Data_Cleaning_EDA.ipynb # Jupyter Notebook for data preparation & EDA
â”‚
â””â”€â”€ README.md # This file
## ğŸ“Š Data Sources (Hypothetical)
The hypothetical data for this project was sourced from three main systems:
1.  **CRM Database:** Customer demographic information (e.g., `tenure`, `Partner`, `Dependents`).
2.  **Billing System:** Services and account information (e.g., `InternetService`, `Contract`, `PaymentMethod`, `MonthlyCharges`).
3.  **Support Ticketing System:** Customer support interaction logs.

## âš™ï¸ Data Preparation Process
The data was prepared through the following steps:
1.  **Data Collection:** Integrating data from multiple hypothetical sources.
2.  **Data Cleaning:** Handling missing values, correcting data types, standardizing categorical values, and removing duplicates.
3.  **Feature Engineering:** Creating new features such as `TenureGroup` and `HasMultipleServices` to improve predictive power.
4.  **Data Integration:** Merging all data into a single, analysis-ready dataset.

## ğŸ”¬ Next Steps
The cleaned dataset is now ready for:
*   Deep-dive Exploratory Data Analysis (EDA)
*   Predictive model building (e.g., Logistic Regression, Random Forest)
*   Generating actionable business insights

## ğŸ› ï¸ Tools & Technologies
*   **Python:** Primary programming language.
*   **Pandas & NumPy:** For data manipulation and cleaning.
*   **Matplotlib & Seaborn:** For data visualization and EDA.
*   **Jupyter Notebook:** For interactive development and documentation.
*   **Git & GitHub:** For version control and project hosting.

---

*This project was created for a course assignment in Business Analytics.*
